{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def transpose_all(x):\n",
    "    a = x.copy()\n",
    "    a = a.T\n",
    "    return x, a\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    w = np.random.randn(dim,1)*0.01\n",
    "    b = 0\n",
    "    return w, b\n",
    "def propagate(w, b, X, Y):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    A = sigmoid(np.dot(w.T,X)+b)                                     # compute activation\n",
    "    cost = (- 1 / m) * np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A)))  # compute cost\n",
    "    \n",
    "    dw =    (1 / m) * np.dot(X, (A - Y).T)\n",
    "    db =    (1 / m) * np.sum(A - Y)\n",
    "    cost = np.squeeze(cost)\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False, print_every=100):\n",
    "    \n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        grads, cost =  propagate(w, b, X, Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        w = w - np.dot(learning_rate, dw)\n",
    "        b = b -  learning_rate* db\n",
    "        if i % 50 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        if print_cost and i % print_every == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs\n",
    "\n",
    "\n",
    "def predict(w, b, X):\n",
    "    \n",
    "    \n",
    "    X, X_T = transpose_all(X)\n",
    "    \n",
    "    m = X_T.shape[1]\n",
    "    w = w.reshape(X_T.shape[0], w.shape[1])\n",
    "    \n",
    "    Y_prediction = sigmoid(np.dot(w.T, X_T)+b)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return Y_prediction.T\n",
    "\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 500, learning_rate = 0.5, print_cost = True,print_every=100):\n",
    "    \n",
    "    \n",
    "    X_train, X_train_T = transpose_all(X_train)\n",
    "    Y_train, Y_train_T = transpose_all(Y_train)\n",
    "    X_test, X_test_T = transpose_all(X_test)\n",
    "    Y_test, Y_test_T = transpose_all(Y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    w, b = initialize_with_zeros(X_train_T.shape[0])\n",
    "\n",
    "    parameters, grads, costs = optimize(w, b, X_train_T, Y_train_T, num_iterations, learning_rate, print_cost, print_every=print_every)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    #Y_prediction_test = predict(w, b, X_test)\n",
    "    #Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "\n",
    "    #print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train_T)) * 100))\n",
    "    #print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test_T)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transpose_all(x):\n",
    "    a = x.copy()\n",
    "    a = a.T\n",
    "    return x, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    w = np.random.randn(dim,1)*0.01\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    A = sigmoid(np.dot(w.T,X)+b)                                     # compute activation\n",
    "    cost = (- 1 / m) * np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A)))  # compute cost\n",
    "    \n",
    "    dw =    (1 / m) * np.dot(X, (A - Y).T)\n",
    "    db =    (1 / m) * np.sum(A - Y)\n",
    "    cost = np.squeeze(cost)\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False, print_every=100):\n",
    "    \n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        grads, cost =  propagate(w, b, X, Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        w = w - np.dot(learning_rate, dw)\n",
    "        b = b -  learning_rate* db\n",
    "        if i % 50 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        if print_cost and i % print_every == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(w, b, X):\n",
    "    \n",
    "    \n",
    "    X, X_T = transpose_all(X)\n",
    "    \n",
    "    m = X_T.shape[1]\n",
    "    w = w.reshape(X_T.shape[0], w.shape[1])\n",
    "    \n",
    "    Y_prediction = sigmoid(np.dot(w.T, X_T)+b)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return Y_prediction.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 500, learning_rate = 0.5, print_cost = True,print_every=100):\n",
    "    \n",
    "    \n",
    "    X_train, X_train_T = transpose_all(X_train)\n",
    "    Y_train, Y_train_T = transpose_all(Y_train)\n",
    "    X_test, X_test_T = transpose_all(X_test)\n",
    "    Y_test, Y_test_T = transpose_all(Y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    w, b = initialize_with_zeros(X_train_T.shape[0])\n",
    "\n",
    "    parameters, grads, costs = optimize(w, b, X_train_T, Y_train_T, num_iterations, learning_rate, print_cost, print_every=print_every)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    #Y_prediction_test = predict(w, b, X_test)\n",
    "    #Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "\n",
    "    #print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train_T)) * 100))\n",
    "    #print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test_T)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8124, 22) (8124, 1)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/mushrooms.csv')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "ch = list(data.columns.values)\n",
    "for i in ch:\n",
    "    encoder = LabelEncoder()\n",
    "    col = data[i]\n",
    "    col = encoder.fit_transform(col)\n",
    "    data[i]=col\n",
    "x = data.drop('class', axis=1).values\n",
    "y = data['class'].values\n",
    "y = y.reshape((-1,1))\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y.toarray(), test_size=.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.388461\n",
      "Cost after iteration 20000: 0.596453\n",
      "Cost after iteration 40000: 0.533062\n",
      "Cost after iteration 60000: 0.496521\n",
      "Cost after iteration 80000: 0.472432\n",
      "Cost after iteration 100000: 0.455265\n",
      "Cost after iteration 120000: 0.442344\n",
      "Cost after iteration 140000: 0.432222\n",
      "Cost after iteration 160000: 0.424049\n",
      "Cost after iteration 180000: 0.417291\n",
      "Cost after iteration 200000: 0.411597\n",
      "Cost after iteration 220000: 0.406723\n",
      "Cost after iteration 240000: 0.402496\n",
      "Cost after iteration 260000: 0.398789\n",
      "Cost after iteration 280000: 0.395506\n"
     ]
    }
   ],
   "source": [
    "d = model(x_train, y_train, x_test, y_test, num_iterations = 300000, learning_rate = 0.001, print_every=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['w'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = predict(d['w'], d['b'], x_train)\n",
    "y_pred = []\n",
    "for i in preds:\n",
    "    y_pred.append(np.argmax(i))\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = []\n",
    "for i in y_train:\n",
    "    y_true.append(np.argmax(i))\n",
    "y_true = np.array(y_true)\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93799046007078013"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load liveness_detection/labels.py\n",
    "import pandas as pd \n",
    "mnist = pd.read_csv('data/mnist.csv')\n",
    "x = mnist.drop(['label'], axis=1).values\n",
    "x = x/255\n",
    "y = mnist.label.values\n",
    "y = y.reshape((-1,1))\n",
    "print(x.shape, y.shape)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "print(x.shape, y.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y.toarray(), test_size=.3, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000, 1)\n"
     ]
    }
   ],
   "source": [
    "x = mnist.drop(['label'], axis=1).values\n",
    "x = x/255\n",
    "y = mnist.label.values\n",
    "y = y.reshape((-1,1))\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "y = enc.fit_transform(y)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y.toarray(), test_size=.3, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 7.158746\n",
      "Cost after iteration 1000: 2.563269\n",
      "Cost after iteration 2000: 2.130130\n",
      "Cost after iteration 3000: 1.874884\n",
      "Cost after iteration 4000: 1.707526\n",
      "Cost after iteration 5000: 1.588647\n",
      "Cost after iteration 6000: 1.499183\n",
      "Cost after iteration 7000: 1.428944\n",
      "Cost after iteration 8000: 1.372012\n",
      "Cost after iteration 9000: 1.324712\n"
     ]
    }
   ],
   "source": [
    "d = model(x_train, y_train, x_test, y_test, num_iterations = 10000, learning_rate = 0.001, print_cost = True, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84751700680272113"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = predict(d['w'], d['b'], x_train)\n",
    "y_pred = []\n",
    "for i in preds:\n",
    "    y_pred.append(np.argmax(i))\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = []\n",
    "for i in y_train:\n",
    "    y_true.append(np.argmax(i))\n",
    "y_true = np.array(y_true)\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
